{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable_baselines3[extra]\n",
    "!pip install pyglet\n",
    "!pip3 install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darius\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# I run this with Python 3.8.8 64-bit\n",
    "# pip install stable_baselines3[extra] \n",
    "# Tutorial video : https://www.youtube.com/watch?v=Mut_u40Sqz4\n",
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import dummy_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enviroment_name = 'CartPole-v0'\n",
    "env = gym.make(enviroment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 0 Score : 11.0\n",
      "Episode : 1 Score : 31.0\n",
      "Episode : 2 Score : 56.0\n",
      "Episode : 3 Score : 9.0\n",
      "Episode : 4 Score : 13.0\n",
      "Episode : 5 Score : 11.0\n",
      "Episode : 6 Score : 12.0\n",
      "Episode : 7 Score : 15.0\n",
      "Episode : 8 Score : 23.0\n",
      "Episode : 9 Score : 18.0\n",
      "Episode : 10 Score : 8.0\n",
      "Episode : 11 Score : 24.0\n",
      "Episode : 12 Score : 16.0\n",
      "Episode : 13 Score : 16.0\n",
      "Episode : 14 Score : 15.0\n",
      "Episode : 15 Score : 27.0\n",
      "Episode : 16 Score : 14.0\n",
      "Episode : 17 Score : 16.0\n",
      "Episode : 18 Score : 32.0\n",
      "Episode : 19 Score : 13.0\n",
      "Episode : 20 Score : 11.0\n",
      "Episode : 21 Score : 15.0\n",
      "Episode : 22 Score : 9.0\n",
      "Episode : 23 Score : 10.0\n",
      "Episode : 24 Score : 11.0\n",
      "Episode : 25 Score : 46.0\n",
      "Episode : 26 Score : 53.0\n",
      "Episode : 27 Score : 11.0\n",
      "Episode : 28 Score : 13.0\n",
      "Episode : 29 Score : 16.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "\n",
    "for episode in range(episodes) :\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done :\n",
    "        # Doesn't work with google colab\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode : {} Score : {}'.format(episode, score))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n",
    "env.observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\\Logs\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training' , 'Logs')\n",
    "print(log_path)\n",
    "\n",
    "env = gym.make(enviroment_name)\n",
    "env = dummy_vec_env.DummyVecEnv([lambda : env])\n",
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 321  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009167844 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006958998 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 78.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025822893 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 69.5         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057548033 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.587       |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 64.5         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008496132 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071146023 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038526815 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.151        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 93.1         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035788151 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 65.2         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050508995 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 68.2         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darius\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:276: UserWarning: Path 'Training\\SavedModels' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)\n",
    "\n",
    "PPO_Path = os.path.join('Training' , 'SavedModels' , 'PPO_ModelCartpole')\n",
    "model.save(PPO_Path)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_Path, env = env)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "920143e87a6f73e79fa1fb141217bbfe64ea7f87745c1ea1e308e551bfb77c5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
